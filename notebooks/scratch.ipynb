{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from buffer import SimpleBuffer\n",
    "from training import train_scae_suite\n",
    "from utils import load_model_with_folded_ln2, load_iterable_dataset\n",
    "from find_top_connections import generate_fake_connections\n",
    "from trainers.scae import SCAESuite\n",
    "from find_top_connections import get_avg_contribs\n",
    "\n",
    "import torch as t\n",
    "from huggingface_hub import login\n",
    "import pickle\n",
    "from transformer_lens import HookedTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import einsum\n",
    "# Jacob's token but feel free to use\n",
    "login(\"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\")\n",
    "device = \"cuda:0\" if t.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#%%\n",
    "DTYPE = t.bfloat16\n",
    "MODEL_NAME = \"roneneldan/TinyStories-33M\"\n",
    "num_tokens = int(10e6)\n",
    "batch_size = 128\n",
    "expansion = 4\n",
    "ctx_len = 128\n",
    "\n",
    "\n",
    "#%%\n",
    "data = load_iterable_dataset('roneneldan/TinyStories')\n",
    "\n",
    "buffer = SimpleBuffer(\n",
    "    data=data,\n",
    "    model_name=MODEL_NAME,\n",
    "    ctx_len=ctx_len,\n",
    "    device=\"cuda\",\n",
    "    batch_size=batch_size,\n",
    "    dtype=DTYPE,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(MODEL_NAME,  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/dictionary_learning/tinystories_connections/top_connections_20.pkl\", \"rb\") as f:\n",
    "    connections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-33M into HookedTransformer\n",
      "Using 2 GPUs for training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99e8786cb1f428ea6ec325573d0e655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_scae_suite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpansion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpansion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mctx_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# use_wandb = True,\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjacobcd52/TinyStories-33M_suite_4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# repo_id_out = \"jacobcd52/TinyStories-33M_scae\",\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# wandb_project_name=\"tinystories33m_scae_4\",\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/notebooks/../training.py:196\u001b[0m, in \u001b[0;36mtrain_scae_suite\u001b[0;34m(buffer, model_name, k, expansion, loss_type, base_lr, steps, connections, save_steps, save_dir, log_steps, use_wandb, repo_id_in, repo_id_out, dtype, device, seed, wandb_project_name, lr_decay_start_proportion, vanilla)\u001b[0m\n\u001b[1;32m    194\u001b[0m cache, tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(buffer)\n\u001b[1;32m    195\u001b[0m module \u001b[38;5;241m=\u001b[39m get_module(suite)\n\u001b[0;32m--> 196\u001b[0m reconstructions \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mvanilla_forward(cache) \u001b[38;5;28;01mif\u001b[39;00m vanilla \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pruned\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Compute MSE loss using FVU\u001b[39;00m\n\u001b[1;32m    199\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/dictionary_learning/notebooks/../trainers/scae.py:254\u001b[0m, in \u001b[0;36mSCAESuite.forward_pruned\u001b[0;34m(self, cache)\u001b[0m\n\u001b[1;32m    251\u001b[0m upstream_bias \u001b[38;5;241m=\u001b[39m upstream_bias \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maes[up_name]\u001b[38;5;241m.\u001b[39mb_dec\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m down_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 254\u001b[0m     contributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pruned_contribs_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdown_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mup_feats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     contributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pruned_contribs_mlp(cache, up_name, down_name, up_feats)\n",
      "File \u001b[0;32m~/dictionary_learning/notebooks/../trainers/scae.py:198\u001b[0m, in \u001b[0;36mSCAESuite.get_pruned_contribs_attn\u001b[0;34m(self, cache, up_name, down_name, up_facts)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Mix between positions using attention pattern\u001b[39;00m\n\u001b[1;32m    197\u001b[0m probs \u001b[38;5;241m=\u001b[39m cache[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.attn.hook_pattern\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 198\u001b[0m contributions \u001b[38;5;241m=\u001b[39m \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontributions_post_ov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch n_heads qpos kpos, batch n_heads kpos f_down -> batch qpos f_down\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contributions\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/einops/einops.py:916\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*tensors_and_pattern)\u001b[0m\n\u001b[1;32m    914\u001b[0m tensors \u001b[38;5;241m=\u001b[39m tensors_and_pattern[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    915\u001b[0m pattern \u001b[38;5;241m=\u001b[39m _compactify_pattern_for_einsum(pattern)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/einops/_backends.py:288\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, pattern, *x)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, pattern, \u001b[38;5;241m*\u001b[39mx):\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/functional.py:386\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    388\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train_scae_suite(\n",
    "    buffer,\n",
    "    model_name=MODEL_NAME,\n",
    "    k=128,\n",
    "    expansion=expansion,\n",
    "    loss_type=\"mse\",\n",
    "    connections=connections,\n",
    "    steps=num_tokens // (batch_size * ctx_len),\n",
    "    save_steps = 1000,\n",
    "    dtype = DTYPE,\n",
    "    device=device,\n",
    "    log_steps = 20,\n",
    "    # use_wandb = True,\n",
    "    repo_id_in='jacobcd52/TinyStories-33M_suite_4',\n",
    "    # repo_id_out = \"jacobcd52/TinyStories-33M_scae\",\n",
    "    # wandb_project_name=\"tinystories33m_scae_4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = SCAESuite(\n",
    "    model=model,\n",
    "    k=128,\n",
    "    n_features=768*4,\n",
    "    connections=connections,\n",
    "    device=device,\n",
    "    dtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache, tokens = next(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_facts = t.randn(128, 128, 4*768, device=device, dtype=DTYPE)\n",
    "contribs = suite.get_pruned_contribs_mlp(\n",
    "    cache,\n",
    "    'attn_0',\n",
    "    'mlp_3',\n",
    "    up_facts\n",
    ")\n",
    "\n",
    "contribs_v2 = suite.get_pruned_contribs_mlp_v2(\n",
    "    cache,\n",
    "    'attn_0',\n",
    "    'mlp_3',\n",
    "    up_facts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1320., device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribs_v2.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, device='cuda:0', dtype=torch.bfloat16, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(contribs - contribs_v2).pow(2).sum()   / (contribs - contribs.mean([0,1])).pow(2).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
