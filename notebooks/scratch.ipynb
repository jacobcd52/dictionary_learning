{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from buffer import SimpleBuffer\n",
    "from training import train_scae_suite\n",
    "from utils import load_model_with_folded_ln2, load_iterable_dataset\n",
    "from find_top_connections import generate_fake_connections\n",
    "from trainers.scae import SCAESuite\n",
    "from find_top_connections import get_avg_contribs\n",
    "\n",
    "import torch as t\n",
    "from huggingface_hub import login\n",
    "import pickle\n",
    "from transformer_lens import HookedTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import einsum\n",
    "# Jacob's token but feel free to use\n",
    "login(\"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\")\n",
    "device = \"cuda:0\" if t.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#%%\n",
    "DTYPE = t.bfloat16\n",
    "MODEL_NAME = \"roneneldan/TinyStories-33M\"\n",
    "num_tokens = int(1e6)\n",
    "batch_size = 256\n",
    "expansion = 4\n",
    "ctx_len = 128\n",
    "\n",
    "\n",
    "#%%\n",
    "data = load_iterable_dataset('roneneldan/TinyStories')\n",
    "\n",
    "buffer = SimpleBuffer(\n",
    "    data=data,\n",
    "    model_name=MODEL_NAME,\n",
    "    ctx_len=ctx_len,\n",
    "    device=\"cuda\",\n",
    "    batch_size=batch_size,\n",
    "    dtype=DTYPE,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(MODEL_NAME,  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/dictionary_learning/tinystories_connections/top_connections_100.pkl\", \"rb\") as f:\n",
    "    connections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-33M into HookedTransformer\n",
      "Using 2 GPUs for training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1646d3d0844efba12068d5ad8a5c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_scae_suite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpansion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpansion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mctx_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# use_wandb = True,\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjacobcd52/TinyStories-33M_suite_4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# repo_id_out = \"jacobcd52/TinyStories-33M_scae\",\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# wandb_project_name=\"tinystories33m_scae_4\",\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/notebooks/../training.py:231\u001b[0m, in \u001b[0;36mtrain_scae_suite\u001b[0;34m(buffer, model_name, k, expansion, loss_type, base_lr, steps, connections, save_steps, save_dir, log_steps, use_wandb, repo_id_in, repo_id_out, dtype, device, seed, wandb_project_name, lr_decay_start_proportion, vanilla)\u001b[0m\n\u001b[1;32m    229\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    230\u001b[0m module \u001b[38;5;241m=\u001b[39m get_module(suite)\n\u001b[0;32m--> 231\u001b[0m reconstructions \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mvanilla_forward(cache) \u001b[38;5;28;01mif\u001b[39;00m vanilla \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pruned\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m loss \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mget_ce_loss(cache, reconstructions, tokens)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Log metrics if requested\u001b[39;00m\n",
      "File \u001b[0;32m~/dictionary_learning/notebooks/../trainers/scae.py:291\u001b[0m, in \u001b[0;36mSCAESuite.forward_pruned\u001b[0;34m(self, cache)\u001b[0m\n\u001b[1;32m    289\u001b[0m         approx_acts \u001b[38;5;241m=\u001b[39m approx_acts \u001b[38;5;241m+\u001b[39m contributions\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m contributions\n\u001b[0;32m--> 291\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Messy bias stuff. Beware bugs.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m down_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py:170\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 170\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train_scae_suite(\n",
    "    buffer,\n",
    "    model_name=MODEL_NAME,\n",
    "    k=128,\n",
    "    expansion=expansion,\n",
    "    loss_type=\"ce\",\n",
    "    connections=connections,\n",
    "    steps=num_tokens // (batch_size * ctx_len),\n",
    "    save_steps = 1000,\n",
    "    dtype = DTYPE,\n",
    "    device=device,\n",
    "    log_steps = 20,\n",
    "    # use_wandb = True,\n",
    "    repo_id_in='jacobcd52/TinyStories-33M_suite_4',\n",
    "    # repo_id_out = \"jacobcd52/TinyStories-33M_scae\",\n",
    "    # wandb_project_name=\"tinystories33m_scae_4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-33M into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4df916383ff48eda985bf2e1aa1ab4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556a2625b515478cb9119c584d96cc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoint.pt:   0%|          | 0.00/597M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/notebooks/../trainers/scae.py:513: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = t.load(checkpoint_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(MODEL_NAME, device=device, dtype=DTYPE)\n",
    "suite = SCAESuite.from_pretrained(\n",
    "    \"jacobcd52/TinyStories-33M_suite_4\",\n",
    "    model,\n",
    "    device=device,\n",
    "    dtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.set_grad_enabled(False)\n",
    "avg_contribs = get_avg_contribs(suite, buffer, n_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from find_top_connections import get_top_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparse tensors to dense...\n",
      "Processing 3072 rows in chunks of 100\n",
      "Current memory usage: 2.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing chunks: 100%|██████████| 31/31 [00:02<00:00, 15.22it/s, mem_usage=2.83GB]\n",
      " 25%|██▌       | 2/8 [00:02<00:06,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparse tensors to dense...\n",
      "Processing 3072 rows in chunks of 100\n",
      "Current memory usage: 2.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing chunks: 100%|██████████| 31/31 [00:02<00:00, 14.72it/s, mem_usage=2.83GB]\n",
      " 38%|███▊      | 3/8 [00:04<00:07,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparse tensors to dense...\n",
      "Processing 3072 rows in chunks of 100\n",
      "Current memory usage: 2.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing chunks: 100%|██████████| 31/31 [00:02<00:00, 13.13it/s, mem_usage=2.83GB]\n",
      " 50%|█████     | 4/8 [00:06<00:07,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparse tensors to dense...\n",
      "Processing 3072 rows in chunks of 100\n",
      "Current memory usage: 2.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing chunks: 100%|██████████| 31/31 [00:02<00:00, 12.37it/s, mem_usage=2.83GB]\n",
      " 62%|██████▎   | 5/8 [00:09<00:06,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparse tensors to dense...\n",
      "Processing 3072 rows in chunks of 100\n",
      "Current memory usage: 2.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing chunks: 100%|██████████| 31/31 [00:02<00:00, 11.64it/s, mem_usage=2.83GB]\n",
      " 75%|███████▌  | 6/8 [00:11<00:04,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparse tensors to dense...\n",
      "Processing 3072 rows in chunks of 100\n",
      "Current memory usage: 2.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing chunks: 100%|██████████| 31/31 [00:02<00:00, 11.47it/s, mem_usage=2.83GB]\n",
      " 88%|████████▊ | 7/8 [00:14<00:02,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparse tensors to dense...\n",
      "Processing 3072 rows in chunks of 100\n",
      "Current memory usage: 2.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing chunks: 100%|██████████| 31/31 [00:02<00:00, 11.44it/s, mem_usage=2.83GB]\n",
      "100%|██████████| 8/8 [00:17<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "avg_contribs = get_avg_contribs(suite, buffer, n_batches=10)\n",
    "inds = get_top_connections(avg_contribs, c=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = (inds['mlp_1']['mlp_0'] != -1).sum(-1).detach().cpu().numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2155.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,  184.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   79.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,   64.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,   46.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,   37.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,   39.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,   59.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   54.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          85.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         270.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,\n",
       "         1.1,  1.2,  1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9,  2. ,  2.1,\n",
       "         2.2,  2.3,  2.4,  2.5,  2.6,  2.7,  2.8,  2.9,  3. ,  3.1,  3.2,\n",
       "         3.3,  3.4,  3.5,  3.6,  3.7,  3.8,  3.9,  4. ,  4.1,  4.2,  4.3,\n",
       "         4.4,  4.5,  4.6,  4.7,  4.8,  4.9,  5. ,  5.1,  5.2,  5.3,  5.4,\n",
       "         5.5,  5.6,  5.7,  5.8,  5.9,  6. ,  6.1,  6.2,  6.3,  6.4,  6.5,\n",
       "         6.6,  6.7,  6.8,  6.9,  7. ,  7.1,  7.2,  7.3,  7.4,  7.5,  7.6,\n",
       "         7.7,  7.8,  7.9,  8. ,  8.1,  8.2,  8.3,  8.4,  8.5,  8.6,  8.7,\n",
       "         8.8,  8.9,  9. ,  9.1,  9.2,  9.3,  9.4,  9.5,  9.6,  9.7,  9.8,\n",
       "         9.9, 10. ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(nums, bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
